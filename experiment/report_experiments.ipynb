{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "from utilities import ROI, ImageTools, PlottingTools\n",
    "import torch\n",
    "from super_gradients.training import models\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_errors(truth_path, estimated_path):\n",
    "    # calculates errors in both translation and rotation\n",
    "    # translation error unit in meters\n",
    "    # rotation error unit in degrees/meter\n",
    "    truth_path = np.array(truth_path)\n",
    "    estimated_path = np.array(estimated_path)\n",
    "    error_translation = np.linalg.norm(truth_path[:, :3, 3] - estimated_path[:, :3, 3], axis=1)\n",
    "    error_rotation = np.linalg.norm(truth_path[:, :3, :3] - estimated_path[:, :3, :3], axis=(1, 2))\n",
    "    # convert rotation error to degrees/meter\n",
    "    error_rotation = np.rad2deg(error_rotation)\n",
    "    # find difference between consecutive frames\n",
    "    error_translation = np.diff(error_translation)\n",
    "    error_rotation = np.diff(error_rotation)\n",
    "    error_rotation = np.abs(error_rotation)\n",
    "    return error_translation, error_rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualOdometry():\n",
    "    def __init__(self, data_path, feature_method=\"orb\", match_threshold=0.5):\n",
    "        self.K, self.P = self._load_calib(os.path.join(data_path, 'calib.txt'))\n",
    "        self.groundtruth_poses = self._load_poses(os.path.join(data_path, 'poses.txt'))\n",
    "        self.images = self._load_images(os.path.join(data_path, 'image_l'))\n",
    "        self.feature_method = feature_method\n",
    "        self.match_threshold = match_threshold\n",
    "        if feature_method == \"orb\":\n",
    "            self.feature_detector = cv2.ORB_create(3000)\n",
    "            FLANN_INDEX_LSH = 6\n",
    "            index_params = dict(algorithm=FLANN_INDEX_LSH, table_number=6, key_size=12, multi_probe_level=1)\n",
    "            search_params = dict(checks=50)\n",
    "        elif feature_method == \"sift\":\n",
    "            self.feature_detector = cv2.SIFT_create()\n",
    "            FLANN_INDEX_KDTREE = 1\n",
    "            index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "            search_params = dict(checks=50)\n",
    "        else:\n",
    "            raise ValueError(\"Feature method not supported\")\n",
    "\n",
    "        self.flann = cv2.FlannBasedMatcher(indexParams=index_params, searchParams=search_params)\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_calib(filepath):\n",
    "        with open(filepath, 'r') as f:\n",
    "            params = np.fromstring(f.readline(), dtype=np.float64, sep=' ')\n",
    "            P = np.reshape(params, (3, 4))\n",
    "            K = P[0:3, 0:3]\n",
    "        return K, P\n",
    "    \n",
    "    @staticmethod\n",
    "    def _load_poses(filepath):\n",
    "        poses = []\n",
    "        with open(filepath, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                T = np.fromstring(line, dtype=np.float64, sep=' ')\n",
    "                T = T.reshape(3, 4)\n",
    "                poses.append(T)\n",
    "        return np.array(poses)\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_images(filepath):\n",
    "        images = []\n",
    "        for filename in sorted(os.listdir(filepath)):\n",
    "            img = cv2.imread(os.path.join(filepath, filename))\n",
    "            images.append(img)\n",
    "        return images\n",
    "    \n",
    "    @staticmethod\n",
    "    def _form_transf(R, t):\n",
    "        T = np.eye(4)\n",
    "        T[:3, :3] = R\n",
    "        T[:3, 3] = t\n",
    "        return T\n",
    "    \n",
    "    def get_matches(self, i):\n",
    "        kp1, des1 = self.feature_detector.detectAndCompute(self.images[i-1], None)\n",
    "        kp2, des2 = self.feature_detector.detectAndCompute(self.images[i], None)\n",
    "        if self.feature_method == \"orb\":\n",
    "            matches = self.flann.knnMatch(des1, des2, k=2)\n",
    "        elif self.feature_method == \"sift\":\n",
    "            matches = self.flann.knnMatch(des1.astype(np.float32), des2.astype(np.float32), k=2)\n",
    "        else:\n",
    "            raise ValueError(\"Feature method not supported\")\n",
    "\n",
    "        good_matches = []\n",
    "        for m, n in matches:\n",
    "            if m.distance < self.match_threshold * n.distance:\n",
    "                good_matches.append(m)\n",
    "        \n",
    "        q1 = np.array([kp1[m.queryIdx].pt for m in good_matches])\n",
    "        q2 = np.array([kp2[m.trainIdx].pt for m in good_matches])\n",
    "\n",
    "        return q1, q2\n",
    "    \n",
    "    def get_pose(self, q1, q2):\n",
    "        # Essential, mask = cv2.findEssentialMat(q1, q2, self.K, cv2.RANSAC, 0.999, 1.0)\n",
    "        Essential, mask = cv2.findEssentialMat(q1, q2, self.K)\n",
    "        R, t = self.decompose(Essential, q1, q2)\n",
    "        return self._form_transf(R, t)\n",
    "    \n",
    "    def decompose(self, Essential, q1, q2):\n",
    "        R1, R2, t = cv2.decomposeEssentialMat(Essential)\n",
    "        T1 = self._form_transf(R1,np.ndarray.flatten(t))\n",
    "        T2 = self._form_transf(R2,np.ndarray.flatten(t))\n",
    "        T3 = self._form_transf(R1,np.ndarray.flatten(-t))\n",
    "        T4 = self._form_transf(R2,np.ndarray.flatten(-t))\n",
    "        transformations = [T1, T2, T3, T4]\n",
    "        K = np.concatenate(( self.K, np.zeros((3,1)) ), axis = 1)\n",
    "        projections = [K @ T1, K @ T2, K @ T3, K @ T4]\n",
    "        np.set_printoptions(suppress=True)\n",
    "        positives = []\n",
    "        for P, T in zip(projections, transformations):\n",
    "            hom_Q1 = cv2.triangulatePoints(self.P, P, q1.T, q2.T)\n",
    "            hom_Q2 = T @ hom_Q1\n",
    "            Q1 = hom_Q1[:3, :] / hom_Q1[3, :]\n",
    "            Q2 = hom_Q2[:3, :] / hom_Q2[3, :]  \n",
    "\n",
    "            total_sum = sum(Q2[2, :] > 0) + sum(Q1[2, :] > 0)\n",
    "            relative_scale = np.mean(np.linalg.norm(Q1.T[:-1] - Q1.T[1:], axis=-1) /\n",
    "                                     (np.linalg.norm(Q2.T[:-1] - Q2.T[1:], axis=-1) + 1e-8))\n",
    "            positives.append(total_sum + relative_scale)\n",
    "        max = np.argmax(positives)\n",
    "        if (max == 2):\n",
    "            return R1, np.ndarray.flatten(-t)\n",
    "        elif (max == 3):\n",
    "            return R2, np.ndarray.flatten(-t)\n",
    "        elif (max == 0):\n",
    "            return R1, np.ndarray.flatten(t)\n",
    "        elif (max == 1):\n",
    "            return R2, np.ndarray.flatten(t)\n",
    "\n",
    "    def get_trajectory(self):\n",
    "        truth_path = []\n",
    "        estimated_path = []\n",
    "        for i, true_pose in enumerate(tqdm(self.groundtruth_poses, unit=\"frame\")):\n",
    "            if i == 0:\n",
    "                current_pose = true_pose\n",
    "            else:\n",
    "                q1, q2 = self.get_matches(i)\n",
    "                estimated_pose = self.get_pose(q1, q2)\n",
    "                current_pose = np.matmul(current_pose, np.linalg.inv(estimated_pose))\n",
    "            truth_path.append(true_pose)\n",
    "            estimated_path.append(current_pose)\n",
    "        return truth_path, estimated_path\n",
    "\n",
    "    def plot_trajectory(self, truth_path, estimated_path):\n",
    "        truth_path = np.array(truth_path)\n",
    "        estimated_path = np.array(estimated_path)\n",
    "        fig = plt.figure()\n",
    "        # set figure size\n",
    "        fig.set_size_inches(20, 10)\n",
    "        # set axis ranges\n",
    "        # plt.xlim((-2.5, 17.5))\n",
    "        plt.plot(truth_path[:, 0, 3], truth_path[:, 2, 3], label='Ground Truth')\n",
    "        plt.plot(estimated_path[:, 0, 3], estimated_path[:, 2, 3], label='Estimated')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_error(self, truth_path, estimated_path):\n",
    "        truth_path = np.array(truth_path)\n",
    "        estimated_path = np.array(estimated_path)\n",
    "        error = np.linalg.norm(truth_path[:, :3, 3] - estimated_path[:, :3, 3], axis=1)\n",
    "        plt.plot(error)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualOdometryWithObjects():\n",
    "    def __init__(self, data_path, feature_method=\"orb\", match_threshold=0.5, iou_threshold=0.5, alpha=0.2):\n",
    "        self.K, self.P = self._load_calib(os.path.join(data_path, 'calib.txt'))\n",
    "        self.groundtruth_poses = self._load_poses(os.path.join(data_path, 'poses.txt'))\n",
    "        self.images = self._load_images(os.path.join(data_path, 'image_l'))\n",
    "        self.feature_method = feature_method\n",
    "        self.match_threshold = match_threshold\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.alpha = alpha\n",
    "        if feature_method == \"orb\":\n",
    "            self.feature_detector = cv2.ORB_create(3000)\n",
    "            FLANN_INDEX_LSH = 6\n",
    "            index_params = dict(algorithm=FLANN_INDEX_LSH, table_number=6, key_size=12, multi_probe_level=1)\n",
    "            search_params = dict(checks=50)\n",
    "        elif feature_method == \"sift\":\n",
    "            self.feature_detector = cv2.SIFT_create()\n",
    "            FLANN_INDEX_KDTREE = 1\n",
    "            index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "            search_params = dict(checks=50)\n",
    "        else:\n",
    "            raise ValueError(\"Feature method not supported\")\n",
    "        self.flann = cv2.FlannBasedMatcher(indexParams=index_params, searchParams=search_params)\n",
    "\n",
    "        # object detection related setup\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = models.get(\"yolo_nas_s\", pretrained_weights=\"coco\").to(self.device)\n",
    "        self.last_bboxes = None\n",
    "        self.last_labels = None\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_calib(filepath):\n",
    "        with open(filepath, 'r') as f:\n",
    "            params = np.fromstring(f.readline(), dtype=np.float64, sep=' ')\n",
    "            P = np.reshape(params, (3, 4))\n",
    "            K = P[0:3, 0:3]\n",
    "        return K, P\n",
    "    \n",
    "    @staticmethod\n",
    "    def _load_poses(filepath):\n",
    "        poses = []\n",
    "        with open(filepath, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                T = np.fromstring(line, dtype=np.float64, sep=' ')\n",
    "                T = T.reshape(3, 4)\n",
    "                poses.append(T)\n",
    "        return np.array(poses)\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_images(filepath):\n",
    "        images = []\n",
    "        for filename in sorted(os.listdir(filepath)):\n",
    "            img = cv2.imread(os.path.join(filepath, filename))\n",
    "            images.append(img)\n",
    "        return images\n",
    "    \n",
    "    @staticmethod\n",
    "    def _form_transf(R, t):\n",
    "        T = np.eye(4)\n",
    "        T[:3, :3] = R\n",
    "        T[:3, 3] = t\n",
    "        return T\n",
    "    \n",
    "    def get_matches(self, i):\n",
    "        kp1, des1 = self.feature_detector.detectAndCompute(self.images[i-1], None)\n",
    "        kp2, des2 = self.feature_detector.detectAndCompute(self.images[i], None)\n",
    "        if self.feature_method == \"orb\":\n",
    "            matches = self.flann.knnMatch(des1, des2, k=2)\n",
    "        elif self.feature_method == \"sift\":\n",
    "            matches = self.flann.knnMatch(des1.astype(np.float32), des2.astype(np.float32), k=2)\n",
    "        else:\n",
    "            raise ValueError(\"Feature method not supported\")\n",
    "\n",
    "        good_matches = []\n",
    "        for m, n in matches:\n",
    "            if m.distance < self.match_threshold * n.distance:\n",
    "                good_matches.append(m)\n",
    "        \n",
    "        q1 = np.array([kp1[m.queryIdx].pt for m in good_matches])\n",
    "        q2 = np.array([kp2[m.trainIdx].pt for m in good_matches])\n",
    "\n",
    "        return q1, q2\n",
    "    \n",
    "    def get_pose(self, q1, q2):\n",
    "        # Essential, mask = cv2.findEssentialMat(q1, q2, self.K, cv2.RANSAC, 0.999, 1.0)\n",
    "        Essential, mask = cv2.findEssentialMat(q1, q2, self.K)\n",
    "        R, t = self.decompose(Essential, q1, q2)\n",
    "        return self._form_transf(R, t)\n",
    "    \n",
    "    def decompose(self, Essential, q1, q2):\n",
    "        R1, R2, t = cv2.decomposeEssentialMat(Essential)\n",
    "        T1 = self._form_transf(R1,np.ndarray.flatten(t))\n",
    "        T2 = self._form_transf(R2,np.ndarray.flatten(t))\n",
    "        T3 = self._form_transf(R1,np.ndarray.flatten(-t))\n",
    "        T4 = self._form_transf(R2,np.ndarray.flatten(-t))\n",
    "        transformations = [T1, T2, T3, T4]\n",
    "        K = np.concatenate(( self.K, np.zeros((3,1)) ), axis = 1)\n",
    "        projections = [K @ T1, K @ T2, K @ T3, K @ T4]\n",
    "        np.set_printoptions(suppress=True)\n",
    "        positives = []\n",
    "        for P, T in zip(projections, transformations):\n",
    "            hom_Q1 = cv2.triangulatePoints(self.P, P, q1.T, q2.T)\n",
    "            hom_Q2 = T @ hom_Q1\n",
    "            Q1 = hom_Q1[:3, :] / hom_Q1[3, :]\n",
    "            Q2 = hom_Q2[:3, :] / hom_Q2[3, :]  \n",
    "\n",
    "            total_sum = sum(Q2[2, :] > 0) + sum(Q1[2, :] > 0)\n",
    "            \"\"\"\n",
    "            relative_scale = np.mean(np.linalg.norm(Q1.T[:-1] - Q1.T[1:], axis=-1)/\n",
    "                                     np.linalg.norm(Q2.T[:-1] - Q2.T[1:], axis=-1))\n",
    "            \"\"\"\n",
    "            relative_scale = np.mean(np.linalg.norm(Q1.T[:-1] - Q1.T[1:], axis=-1) /\n",
    "                                     (np.linalg.norm(Q2.T[:-1] - Q2.T[1:], axis=-1) + 1e-8))\n",
    "            positives.append(total_sum + relative_scale)\n",
    "        max = np.argmax(positives)\n",
    "        if (max == 2):\n",
    "            return R1, np.ndarray.flatten(-t)\n",
    "        elif (max == 3):\n",
    "            return R2, np.ndarray.flatten(-t)\n",
    "        elif (max == 0):\n",
    "            return R1, np.ndarray.flatten(t)\n",
    "        elif (max == 1):\n",
    "            return R2, np.ndarray.flatten(t)\n",
    "    \n",
    "    def get_objects(self, i):\n",
    "        # prediction = self.model.predict(self.images[i])\n",
    "        for item in self.model.predict(self.images[i], conf=0.6)._images_prediction_lst:\n",
    "            bboxes = item.prediction.bboxes_xyxy\n",
    "            labels = item.prediction.labels\n",
    "            return bboxes, labels\n",
    "        return None, None\n",
    "    \n",
    "    def match_objects(self, bboxes1, bboxes2, labels1, labels2):\n",
    "        matches = []\n",
    "        for i, bbox1 in enumerate(bboxes1):\n",
    "            for j, bbox2 in enumerate(bboxes2):\n",
    "                if labels1[i] == labels2[j]:\n",
    "                    box1 = bbox1\n",
    "                    box2 = bbox2\n",
    "                    iou = self.compute_iou(box1, box2)\n",
    "                    if iou > self.iou_threshold:\n",
    "                        matches.append((i, j))\n",
    "        return matches\n",
    "    \n",
    "    def compute_iou(self, box1, box2):\n",
    "        \"\"\"\n",
    "        Computes IoU (Intersection over Union) between two bounding boxes\n",
    "        IoU is a metric for evaluating simularity between two bounding boxes\n",
    "        IoU is a value between 0 and 1, where 1 means the two bounding boxes are identical\n",
    "        \"\"\"\n",
    "        x1, y1, x2, y2 = box1\n",
    "        x3, y3, x4, y4 = box2\n",
    "        x5, y5, x6, y6 = (max(x1, x3), max(y1, y3), min(x2, x4), min(y2, y4))\n",
    "        if x5 > x6 or y5 > y6:\n",
    "            return 0\n",
    "        else:\n",
    "            intersection = (x6 - x5) * (y6 - y5)\n",
    "            union = (x2 - x1) * (y2 - y1) + (x4 - x3) * (y4 - y3) - intersection\n",
    "            return intersection / union\n",
    "    \n",
    "    def get_pose_from_object(self, object_matches, new_bboxes):\n",
    "        translations = []\n",
    "\n",
    "        for match in object_matches:\n",
    "            i, j = match\n",
    "            bbox1 = self.last_bboxes[i]\n",
    "            bbox2 = new_bboxes[j]\n",
    "\n",
    "            centroid1 = np.array([(bbox1[0] + bbox1[2]) / 2, (bbox1[1] + bbox1[3]) / 2])\n",
    "            centroid2 = np.array([(bbox2[0] + bbox2[2]) / 2, (bbox2[1] + bbox2[3]) / 2])\n",
    "\n",
    "            translation = centroid2 - centroid1\n",
    "            translations.append(translation)\n",
    "\n",
    "        avg_translation = np.mean(translations, axis=0)\n",
    "        R = np.eye(3)\n",
    "        t = np.array([avg_translation[0], 0, avg_translation[1]])\n",
    "\n",
    "        return self._form_transf(R, t)\n",
    "\n",
    "    def get_trajectory(self):\n",
    "        truth_path = []\n",
    "        estimated_path = []\n",
    "        for i, true_pose in enumerate(tqdm(self.groundtruth_poses, unit=\"frame\")):\n",
    "            if i == 0:\n",
    "                current_pose = true_pose\n",
    "                self.last_bboxes, self.last_labels = self.get_objects(i)\n",
    "            else:\n",
    "                q1, q2 = self.get_matches(i)\n",
    "                estimated_pose_from_feature = self.get_pose(q1, q2)\n",
    "                \n",
    "                # object detection related code\n",
    "                bboxes, labels = self.get_objects(i)\n",
    "                object_matches = self.match_objects(self.last_bboxes, bboxes, self.last_labels, labels)\n",
    "                # print(len(object_matches))\n",
    "                if len(object_matches) > 0:\n",
    "                    estimated_pose_from_object = self.get_pose_from_object(object_matches, bboxes)\n",
    "                    # if estimated_pose_from_object is too large, we ignore it\n",
    "                    object_pose_norm = np.linalg.norm(estimated_pose_from_object[:3, 3])\n",
    "                    # print(object_pose_norm)\n",
    "                    if object_pose_norm > 5.0:\n",
    "                        estimated_pose = estimated_pose_from_feature\n",
    "                    else:\n",
    "                        estimated_pose = (1-self.alpha)*estimated_pose_from_feature + self.alpha*estimated_pose_from_object\n",
    "                else:\n",
    "                    estimated_pose = estimated_pose_from_feature\n",
    "                self.last_bboxes = bboxes\n",
    "                self.last_labels = labels\n",
    "\n",
    "                current_pose = np.matmul(current_pose, np.linalg.inv(estimated_pose))\n",
    "            truth_path.append(true_pose)\n",
    "            estimated_path.append(current_pose)\n",
    "        return truth_path, estimated_path\n",
    "\n",
    "    def plot_trajectory(self, truth_path, estimated_path):\n",
    "        truth_path = np.array(truth_path)\n",
    "        estimated_path = np.array(estimated_path)\n",
    "        fig = plt.figure()\n",
    "        plt.plot(truth_path[:, 0, 3], truth_path[:, 2, 3], label='Ground Truth')\n",
    "        plt.plot(estimated_path[:, 0, 3], estimated_path[:, 2, 3], label='Estimated')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_error(self, truth_path, estimated_path):\n",
    "        truth_path = np.array(truth_path)\n",
    "        estimated_path = np.array(estimated_path)\n",
    "        error = np.linalg.norm(truth_path[:, :3, 3] - estimated_path[:, :3, 3], axis=1)\n",
    "        plt.plot(error)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualOdometryWithROI_Enhanced():\n",
    "    def __init__(self, K, P, groundtruth_poses, images, feature_method=\"orb\", match_threshold=0.5, roi_resolution=1200, roi_threshold_low=0, roi_threshold_high=1000) -> None:\n",
    "        self.K = K\n",
    "        self.P = P\n",
    "        self.groundtruth_poses = groundtruth_poses\n",
    "        self.images = images\n",
    "        self.feature_method = feature_method\n",
    "        if feature_method == \"orb\":\n",
    "            self.feature_detector = cv2.ORB_create(3000)\n",
    "            FLANN_INDEX_LSH = 6\n",
    "            index_params = dict(algorithm=FLANN_INDEX_LSH, table_number=6, key_size=12, multi_probe_level=1)\n",
    "            search_params = dict(checks=50)\n",
    "        elif feature_method == \"sift\":\n",
    "            self.feature_detector = cv2.SIFT_create()\n",
    "            FLANN_INDEX_KDTREE = 1\n",
    "            index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "            search_params = dict(checks=50)\n",
    "        else:\n",
    "            raise ValueError(\"Feature method not supported\")\n",
    "        self.flann = cv2.FlannBasedMatcher(indexParams=index_params, searchParams=search_params)\n",
    "\n",
    "        # ROI related\n",
    "        self.roi_object = ROI(max_dimension=roi_resolution,\n",
    "                              roi_threshold_low=roi_threshold_low,\n",
    "                              roi_threshold_high=roi_threshold_high)\n",
    "        self.roi_object1 = ROI(max_dimension=1200,\n",
    "                              roi_threshold_low=roi_threshold_low,\n",
    "                              roi_threshold_high=roi_threshold_high)\n",
    "        self.last_kp = None\n",
    "        self.last_des = None\n",
    "        self.match_threshold = match_threshold\n",
    "        self.last_roi = None\n",
    "\n",
    "        # for new enhancements\n",
    "        self.current_transformation = np.eye(4)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _form_transf(R, t):\n",
    "        T = np.eye(4)\n",
    "        T[:3, :3] = R\n",
    "        T[:3, 3] = t\n",
    "        return T\n",
    "    \n",
    "    def get_matches(self, i):\n",
    "        kp1, des1 = self.feature_detector.detectAndCompute(self.images[i-1], None)\n",
    "        kp2, des2 = self.feature_detector.detectAndCompute(self.images[i], None)\n",
    "        if self.feature_method == \"orb\":\n",
    "            matches = self.flann.knnMatch(des1, des2, k=2)\n",
    "        elif self.feature_method == \"sift\":\n",
    "            matches = self.flann.knnMatch(des1.astype(np.float32), des2.astype(np.float32), k=2)\n",
    "        else:\n",
    "            raise ValueError(\"Feature method not supported\")\n",
    "\n",
    "        good_matches = []\n",
    "        for m, n in matches:\n",
    "            if m.distance < self.match_threshold * n.distance:\n",
    "                good_matches.append(m)\n",
    "        \n",
    "        q1 = np.array([kp1[m.queryIdx].pt for m in good_matches])\n",
    "        q2 = np.array([kp2[m.trainIdx].pt for m in good_matches])\n",
    "\n",
    "        return q1, q2\n",
    "    \n",
    "    def get_matches_roi(self, i, roi):\n",
    "        kp1 = self.last_kp\n",
    "        des1 = self.last_des\n",
    "        kp2, des2 = self.get_kp_des(i, roi)\n",
    "        self.last_kp = kp2\n",
    "        self.last_des = des2\n",
    "        if self.feature_method == \"orb\":\n",
    "            matches = self.flann.knnMatch(np.array(des1), np.array(des2), k=2)\n",
    "        elif self.feature_method == \"sift\":\n",
    "            matches = self.flann.knnMatch(np.array(des1).astype(np.float32), np.array(des2).astype(np.float32), k=2)\n",
    "        else:\n",
    "            raise ValueError(\"Feature method not supported\")\n",
    "        good_matches = []\n",
    "        if len(matches) > 0:\n",
    "            for m, n in matches:\n",
    "                if m.distance < self.match_threshold * n.distance:\n",
    "                    good_matches.append(m)\n",
    "        q1 = np.array([kp1[m.queryIdx].pt for m in good_matches])\n",
    "        q2 = np.array([kp2[m.trainIdx].pt for m in good_matches])\n",
    "        return q1, q2, kp2\n",
    "    \n",
    "    def get_kp_des(self, i, rois):\n",
    "        kp_list = []\n",
    "        des_list = []\n",
    "        for roi in rois:\n",
    "            roi_img = self.images[i][roi[1]:roi[1]+roi[3], roi[0]:roi[0]+roi[2]]\n",
    "            kp, des = self.feature_detector.detectAndCompute(roi_img, None)\n",
    "            for k in kp:\n",
    "                k.pt = (k.pt[0] + roi[0], k.pt[1] + roi[1])\n",
    "            if len(kp) == 0:\n",
    "                continue\n",
    "            kp_list.extend(kp)\n",
    "            des_list.extend(des)\n",
    "        return kp_list, des_list\n",
    "    \n",
    "    def get_pose(self, q1, q2):\n",
    "        # Essential, mask = cv2.findEssentialMat(q1, q2, self.K, cv2.RANSAC, 0.999, 1.0)\n",
    "        Essential, _ = cv2.findEssentialMat(q1, q2, self.K)\n",
    "        R, t = self.decompose(Essential, q1, q2)\n",
    "        return self._form_transf(R, t)\n",
    "    \n",
    "    def decompose(self, Essential, q1, q2):\n",
    "        R1, R2, t = cv2.decomposeEssentialMat(Essential)\n",
    "        T1 = self._form_transf(R1,np.ndarray.flatten(t))\n",
    "        T2 = self._form_transf(R2,np.ndarray.flatten(t))\n",
    "        T3 = self._form_transf(R1,np.ndarray.flatten(-t))\n",
    "        T4 = self._form_transf(R2,np.ndarray.flatten(-t))\n",
    "        transformations = [T1, T2, T3, T4]\n",
    "        K = np.concatenate(( self.K, np.zeros((3,1)) ), axis = 1)\n",
    "        projections = [K @ T1, K @ T2, K @ T3, K @ T4]\n",
    "        np.set_printoptions(suppress=True)\n",
    "        positives = []\n",
    "        for P, T in zip(projections, transformations):\n",
    "            hom_Q1 = cv2.triangulatePoints(self.P, P, q1.T, q2.T)\n",
    "            hom_Q2 = T @ hom_Q1\n",
    "            Q1 = hom_Q1[:3, :] / hom_Q1[3, :]\n",
    "            Q2 = hom_Q2[:3, :] / hom_Q2[3, :]  \n",
    "            total_sum = sum(Q2[2, :] > 0) + sum(Q1[2, :] > 0)\n",
    "            relative_scale = np.mean(np.linalg.norm(Q1.T[:-1] - Q1.T[1:], axis=-1) /\n",
    "                                     (np.linalg.norm(Q2.T[:-1] - Q2.T[1:], axis=-1) + 1e-8))\n",
    "            positives.append(total_sum + relative_scale)\n",
    "        max = np.argmax(positives)\n",
    "        if (max == 2):\n",
    "            return R1, np.ndarray.flatten(-t)\n",
    "        elif (max == 3):\n",
    "            return R2, np.ndarray.flatten(-t)\n",
    "        elif (max == 0):\n",
    "            return R1, np.ndarray.flatten(t)\n",
    "        elif (max == 1):\n",
    "            return R2, np.ndarray.flatten(t)\n",
    "    \n",
    "    def filter_roi_with_IoU(self, rois):\n",
    "        new_rois = []\n",
    "        for roi in rois:\n",
    "            if len(new_rois) == 0:\n",
    "                new_rois.append(roi)\n",
    "            else:\n",
    "                iou = []\n",
    "                for new_roi in new_rois:\n",
    "                    iou.append(self._get_iou(roi, new_roi))\n",
    "                if max(iou) < 0.5:\n",
    "                    new_rois.append(roi)\n",
    "        return new_rois\n",
    "    \n",
    "    def _get_iou(self, roi1, roi2):\n",
    "        x1 = max(roi1[0], roi2[0])\n",
    "        y1 = max(roi1[1], roi2[1])\n",
    "        x2 = min(roi1[0] + roi1[2], roi2[0] + roi2[2])\n",
    "        y2 = min(roi1[1] + roi1[3], roi2[1] + roi2[3])\n",
    "        intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "        union = roi1[2] * roi1[3] + roi2[2] * roi2[3] - intersection\n",
    "        return intersection / union\n",
    "\n",
    "    def get_trajectory(self):\n",
    "        truth_path = []\n",
    "        estimated_path = []\n",
    "        time_array1 = []\n",
    "        time_array2 = []\n",
    "        for i, true_pose in enumerate(tqdm(self.groundtruth_poses, unit=\"frame\")):\n",
    "            if i == 0:\n",
    "                current_pose = true_pose\n",
    "                roi = self.roi_object.get_rois(self.images[i])\n",
    "                self.last_kp, self.last_des = self.get_kp_des(i, roi)\n",
    "            else:\n",
    "                # time1 = time.time()\n",
    "                roi = self.roi_object.get_rois(self.images[i])\n",
    "                # roi = self.filter_roi_with_IoU(roi)\n",
    "                \n",
    "                q1, q2, new_keypoints = self.get_matches_roi(i, roi)\n",
    "                # self.plot_roi_and_keypoints(i, roi, new_keypoints)\n",
    "                \n",
    "                # time2 = time.time()\n",
    "                # _ = self.roi_object1.get_rois(self.images[i])\n",
    "                # q11, q22 = self.get_matches(i)\n",
    "                # time_array2.append(time.time() - time2)\n",
    "                new_transformation = self.get_pose(q1, q2)\n",
    "                # time_array1.append(time.time() - time1)\n",
    "\n",
    "\n",
    "\n",
    "                # time2 = time.time()\n",
    "                # _ = self.roi_object.get_rois(self.images[i])              \n",
    "                # q11, q22, new_keypoints = self.get_matches_roi(i, roi)\n",
    "                # self.plot_roi_and_keypoints(i, roi, new_keypoints)\n",
    "                # new_transformation1 = self.get_pose(q1, q2)\n",
    "                # time_array2.append(time.time() - time2)\n",
    "\n",
    "                # weigh the new transformation with the previous one\n",
    "                # filtered_transformation = new_transformation\n",
    "                filtered_transformation = self.current_transformation * 0.5 + new_transformation * 0.5\n",
    "                \n",
    "                current_pose = np.matmul(current_pose, np.linalg.inv(filtered_transformation))\n",
    "                self.current_transformation = new_transformation\n",
    "            truth_path.append(true_pose)\n",
    "            estimated_path.append(current_pose)\n",
    "        return truth_path, estimated_path\n",
    "    \n",
    "    def plot_roi_and_keypoints(self, i, roi, keypoints):\n",
    "        img = self.images[i].copy()\n",
    "        for r in roi:\n",
    "            cv2.rectangle(img, (r[0], r[1]), (r[0]+r[2], r[1]+r[3]), (0, 255, 0), 2)\n",
    "        img = cv2.drawKeypoints(img, keypoints, None, color=(0, 255, 0), flags=0)\n",
    "        # use a cv2 window to display images\n",
    "        cv2.imshow('ROI & keypoints', img)\n",
    "        cv2.waitKey(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"KITTI_sequence_1\"\n",
    "image_tools = ImageTools(data_path)\n",
    "K, P, path, images = image_tools.read_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:09<00:00,  5.55frame/s]\n",
      "100%|██████████| 51/51 [00:08<00:00,  5.97frame/s]\n",
      "100%|██████████| 51/51 [00:08<00:00,  6.05frame/s]\n",
      "100%|██████████| 51/51 [00:08<00:00,  5.95frame/s]\n",
      "100%|██████████| 51/51 [00:09<00:00,  5.58frame/s]\n",
      "100%|██████████| 51/51 [00:08<00:00,  5.85frame/s]\n",
      "100%|██████████| 51/51 [00:09<00:00,  5.66frame/s]\n",
      "100%|██████████| 51/51 [00:09<00:00,  5.64frame/s]\n",
      " 96%|█████████▌| 49/51 [00:08<00:00,  5.21frame/s]"
     ]
    }
   ],
   "source": [
    "translation_errors = []\n",
    "rotation_errors = []\n",
    "run_times = []\n",
    "for i in range(1, 10):\n",
    "    curr_time = time.time()\n",
    "    # vo = VisualOdometryWithObjects(data_path, feature_method='sift')\n",
    "    \n",
    "    vo = VisualOdometryWithROI_Enhanced(K,\n",
    "                                        P, \n",
    "                                        path, \n",
    "                                        images, \n",
    "                                        feature_method=\"sift\", \n",
    "                                        roi_resolution=1200, \n",
    "                                        roi_threshold_low=10, \n",
    "                                        roi_threshold_high=1000)\n",
    "    \n",
    "    truth_path, estimated_path = vo.get_trajectory()\n",
    "    error_translation, error_rotation = calculate_errors(truth_path, estimated_path)\n",
    "    translation_errors.append(np.average(error_translation))\n",
    "    rotation_errors.append(np.average(error_rotation))\n",
    "    run_times.append(time.time() - curr_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:09<00:00,  5.64frame/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.20763492103907144"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(translation_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.057792513291024465"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(rotation_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.855145454406738"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(run_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_errors = [0.19774, 0.21509, 0.29486, 0.19785, 0.19765, 0.20763]\n",
    "average_runtime = [18.47078, 3.25652, 30.25726, 5.60529, 8.55820, 8.85514]\n",
    "methods = [\"VO SIFT\", \"VO ORB\", \"Object VO\", \"ROI-SIFT 1\", \"ROI-SIFT 2\", \"ROI-SIFT 3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw a 2D scatter plot of the motion errors and the runtimes\n",
    "# mark each point with a different color\n",
    "# add a legend\n",
    "# add axis labels\n",
    "\n",
    "plt.scatter(motion_errors, average_runtime)\n",
    "for i, method in enumerate(methods):\n",
    "    offset = 0.1\n",
    "    offset1 = 0.001\n",
    "    if method=='ROI-SIFT 2':\n",
    "        offset = 0.4\n",
    "        offset1 = -0.017\n",
    "    elif method=='ROI-SIFT 3':\n",
    "        offset = 0.3\n",
    "    plt.annotate(method, (motion_errors[i], average_runtime[i]), xytext=(motion_errors[i]+offset1, average_runtime[i]+offset))\n",
    "# set x axis limits\n",
    "plt.xlim(0.18, 0.32)\n",
    "plt.xlabel(\"Translation Error\")\n",
    "plt.ylabel(\"Average Runtime\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
